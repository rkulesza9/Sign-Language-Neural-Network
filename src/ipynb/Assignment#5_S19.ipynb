{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Tensorflow - Part IV - Implementation of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First reset the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import a few other packages some included others provided to you for this project\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kules\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant(9, dtype=tf.float32, name='y')                   #Define y, and set to 9\n",
    "y_hat = tf.constant(5, dtype=tf.float32, name='y_hat')           #Define y_hat and set it to 5\n",
    "loss = tf.Variable((y-y_hat)**2,dtype=tf.float32, name='loss')   #define loss as variable and its calcualtion\n",
    "\n",
    "init = tf.global_variables_initializer()                         #initialize everything\n",
    "\n",
    "with tf.Session() as sess:                                       #now run the session\n",
    "    sess.run(init)\n",
    "    print(loss.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing and running programs in TensorFlow cab be decribed as these 5 steps:\n",
    "\n",
    "1. Create Tensors (variables) that are not yet executed/evaluated. \n",
    "2. Write operations between those Tensors.\n",
    "\n",
    "3. Initialize your Tensors. \n",
    "4. Create a Session. \n",
    "5. Run the Session. This will run the operations you'd written above. \n",
    "\n",
    "The first two creates the Tensorflow graph and the last 3 involves evaluating the graph.\n",
    "\n",
    "Therefore, when we created a variable for the loss, we simply defined the loss as a function of other quantities, but did not evaluate its value. To evaluate it, we had to run `init=tf.global_variables_initializer()`. That initialized the loss variable, and in the last line we were finally able to evaluate the value of `loss` and print its value.\n",
    "\n",
    "Now let us look at another easy example. Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sub_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(5, dtype=tf.float32, name='x')\n",
    "y = tf.constant(3, dtype=tf.float32, name='y')\n",
    "f = x**2 + y -3\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(f.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Great! To summarize, remember to **initialize your variables, create a session and run the operations inside the session.**\n",
    "\n",
    "Next, we are take look at placeholders. It is an important utility in Tensorflow.  A placeholder is an object whose value you can specify only later. To specify values for a placeholder, you can pass in values by using a \"feed dictionary\" (feed_dict variable). Below, we created a placeholder for x. This allows us to pass in a number later when we run the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =  -3.0\n",
      "y =  -2.0\n",
      "y =  1.0\n",
      "y =  6.0\n",
      "y =  13.0\n",
      "y =  22.0\n",
      "y =  33.0\n",
      "y =  46.0\n",
      "y =  61.0\n",
      "y =  78.0\n"
     ]
    }
   ],
   "source": [
    "#define x as palceholder for an number (float32 type in this case)\n",
    "x = tf.placeholder(dtype=tf.float32, name='x')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for val in range(10):\n",
    "        #val of x are fed in for x at each step and calculate the y-values\n",
    "        y = sess.run(x**2 -3, feed_dict={x:val})\n",
    "        print('y = ', y)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EX 1.\n",
    "#### Randomly initiate two vectors of dimension 10 in Tensorflow and calcuate the euclidean disance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9352398\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x1 = tf.placeholder(dtype=tf.float32, shape=[10], name='x1')\n",
    "x2 = tf.placeholder(dtype=tf.float32, shape=[10], name='x2')\n",
    "dist = tf.sqrt(tf.reduce_sum(tf.square(x1-x2)))\n",
    "\n",
    "dictt = dict()\n",
    "dictt[x1] = np.random.randn(10)\n",
    "dictt[x2] = np.random.randn(10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    dist = sess.run(dist, feed_dict=dictt)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first defined `x` you did not have to specify a value for it. A placeholder is simply a variable that you will assign data to only later, when running the session. We say that you **feed data** to these placeholders when running the session. \n",
    "\n",
    "Here's what's happening: When you specify the operations needed for a computation, you are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values you will specify only later. Finally, when you run the session, you are telling TensorFlow to execute the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now we are going to start putting together the elements that we need to implement neural networks algorithm in steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let us try to get matrix multiplication in Tensorflow working right for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = [[3.89938082 3.89938082]\n",
      " [6.14472371 6.14472371]\n",
      " [5.90159072 5.90159072]\n",
      " [5.50249434 5.50249434]\n",
      " [5.90085595 5.90085595]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.constant(np.ones([5,5]), name = \"X\")\n",
    "W = tf.constant(np.ones([5,2]), name = \"W\")\n",
    "b = tf.constant(np.random.randn(5,1), name = \"b\")\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(tf.add(tf.matmul(X,W),b))\n",
    "    print('z =', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exercise 2:  \n",
    " #### Define three matrices of dimensions 3x3, 3x4, and 4x4 of random numbers as tensor constants and and calculate the product of all three using Tensorflow </color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1:  [[1.6376138 9.015155  8.805347 ]\n",
      " [4.0429068 2.9545856 3.3601058]\n",
      " [3.2843328 2.3481107 4.79424  ]]\n",
      "m2:  [[9.853394  8.788494  4.856735  4.311963 ]\n",
      " [7.5058246 1.5067458 0.4169774 3.2545424]\n",
      " [1.5525901 4.2622805 6.7423544 8.861276 ]]\n",
      "m3:  [[7.374016   5.0932813  0.58565855 7.4639797 ]\n",
      " [8.329463   9.170397   9.827399   3.7922823 ]\n",
      " [0.78127384 6.058632   2.571025   4.896269  ]\n",
      " [1.4031482  8.543531   9.286342   6.7104254 ]]\n",
      "result:  [[2263.9229 1303.5292 2546.9397 1683.8037]\n",
      " [1774.635  1037.498  2020.506  1245.8259]\n",
      " [2319.7334 1330.837  2617.2427 1654.3594]]\n"
     ]
    }
   ],
   "source": [
    "m1 = tf.random.uniform([3,3],0,10)\n",
    "m2 = tf.random.uniform([3,4],0,10)\n",
    "m3 = tf.random.uniform([4,4],0,10)\n",
    "\n",
    "result = tf.matmul(tf.matmul(m1,m2),m3)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"m1: \",m1.eval())\n",
    "    print(\"m2: \",m2.eval())\n",
    "    print(\"m3: \",m3.eval())\n",
    "    print(\"result: \",result.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear function (hypothesis) calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_fun(X, W, b):\n",
    "    z = tf.add(tf.matmul(X,W), b)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr = np.random.randn(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 4.62737425, -1.69324339,  0.92007405,  2.99304044, -2.50177457,\n",
      "        -0.45683678,  3.20199762, -2.42816813,  6.22272206, -1.64962547,\n",
      "        -3.6257785 , -2.49528668,  2.43891757,  2.22727518, -1.48238289,\n",
      "        -4.78707147, -1.40704019,  5.66844999, -1.26449309,  0.89697317],\n",
      "       [-1.89259926, -0.2213172 , -3.437651  ,  0.2937006 ,  0.74708009,\n",
      "        -2.71666738, -0.28484516, -0.69911654, -1.73927413,  0.74653693,\n",
      "         1.38692545,  4.276587  ,  0.9710673 , -0.06279389, -0.3905815 ,\n",
      "         2.73713401, -0.65487695, -1.27293267, -1.02699808,  1.74792675],\n",
      "       [ 2.41740599,  0.17966539, -3.86559159, -1.85116677,  1.24332134,\n",
      "        -4.51650803,  2.91184696,  2.86649683, -0.95066753,  1.43532332,\n",
      "         2.79845187, -2.26473934,  3.67224225, -0.9128823 ,  7.25634433,\n",
      "        -0.69043275, -3.03226484,  4.08194484,  0.5746102 ,  1.57566876],\n",
      "       [-2.46866651, -0.39065236, -0.60933301, -0.5641226 ,  2.37432786,\n",
      "        -2.23169274, -1.58291303,  0.66333944, -0.78786404, -3.76906623,\n",
      "        -0.62795442,  0.93627734,  1.24277192,  2.4609833 ,  1.14911869,\n",
      "         1.62556766,  0.40135288,  1.09096666, -0.32105608,  1.00170095],\n",
      "       [-0.78843466,  2.37307714, -6.54373903,  0.69535754, -0.84767821,\n",
      "        -1.66505292, -2.01476479, -1.388443  ,  1.23277734, -2.46804055,\n",
      "        -2.09462765,  8.94395567,  1.74573095, -3.20206041,  4.49112314,\n",
      "         7.09612412, -3.04105537, -6.96047337, -1.60090268,  0.17519618],\n",
      "       [-1.41888515,  2.11694006, -3.33212429,  1.06893262, -3.66854655,\n",
      "        -3.23080193, -0.19564498, -3.31459728,  2.5268617 , -2.40496372,\n",
      "         0.85091156,  4.92113716,  4.26436479,  2.74484834,  5.13230591,\n",
      "         1.09432982, -3.92155855,  0.12543984,  0.42222047, -0.37604546],\n",
      "       [ 1.5021213 , -0.63032969, -4.63181316,  1.48031647,  0.99333619,\n",
      "        -1.07116031,  4.20127738, -0.67901956, -0.01462573,  2.0709571 ,\n",
      "        -0.25523215,  0.83193247, -0.74761198, -5.20095468, -0.60803587,\n",
      "         0.16034314,  1.97290878, -3.72976314,  1.26810022,  2.39781746],\n",
      "       [-2.41571513,  3.94286093,  1.34423948, -0.13655506, -5.39824098,\n",
      "        -0.94499943,  1.79620315, -4.05072826, -0.61386333,  2.2240012 ,\n",
      "         5.09499592,  0.74711751,  3.96763358,  2.53727028,  5.30916152,\n",
      "        -0.89044371, -4.32718651,  0.85581956,  4.73285105, -2.07775161],\n",
      "       [-3.01678397,  3.49557843, -2.78250109,  0.61661706,  2.46615806,\n",
      "         1.56760407, -6.33899465,  4.6299402 , -9.33218602, 12.56211118,\n",
      "         9.95204748,  5.7442132 , -3.72275704,  1.26945669, -0.25493049,\n",
      "         1.7562047 , -0.08339566,  1.42841029,  0.80590375,  1.57056096],\n",
      "       [ 5.16229308,  2.03971048, -1.85453256, -0.93744587, -0.20607431,\n",
      "         1.00767021, -1.39368406, -3.14567306,  1.11709805,  8.5165001 ,\n",
      "         0.25303804,  2.45593533, -5.32411238, -9.87093976,  0.6444208 ,\n",
      "         3.43290755, -2.51829693, -4.2195579 , -2.09829224, -2.84226231]])]\n"
     ]
    }
   ],
   "source": [
    "#X = tf.placeholder(tf.float64,shape=(10,10), name='X')\n",
    "#W = tf.placeholder(tf.float64, shape=(10,10), name='W')\n",
    "Xr = np.random.randn(10,10)\n",
    "W1 = np.random.randn(10,20)\n",
    "b1 = np.random.randn(1)\n",
    "X = tf.placeholder(tf.float64, name='X')\n",
    "W = tf.placeholder(tf.float64, name='W')\n",
    "b = tf.placeholder(tf.float64, name='b')\n",
    "#W1 = tf.constant(np.random.randn(10,10), name = \"W1\")\n",
    "#b1 = tf.constant(np.random.randn(1,1))\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run([lin_fun(X,W,b)], feed_dict={X:Xr, W:W1, b:b1})\n",
    "    #Let us verify we are getting the right matriz out\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This following is one step of the neural network calcualtion: from input to ready for activation using the function we just defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = [[-2.24152505 -1.90377908  0.10518085 -0.87580661 -0.28258289  0.0369864\n",
      "  -1.02475681  1.50358803  1.55950109  0.56875331]]\n",
      "b =  [[ 0.68400133 -0.35340998 -1.78791289  0.36184732 -0.42449279 -0.73153098\n",
      "  -1.56573815  1.01382247 -2.22711263 -1.6993336 ]]\n",
      "z = [[-1.55752372 -2.25718906 -1.68273204 -0.51395929 -0.70707568 -0.69454458\n",
      "  -2.59049496  2.5174105  -0.66761155 -1.13058029]]\n"
     ]
    }
   ],
   "source": [
    "#For linear function calculation for 10 nodes with 10 feature inputs\n",
    "tf.reset_default_graph()\n",
    "#first the fearure vector of dimension 1x10\n",
    "X = tf.constant(np.random.randn(1,10), name = \"X\")\n",
    "#the weights matrix W of dimension 10x10 that produces 10 activations\n",
    "W = tf.constant(np.random.randn(10,10), name = \"W\")\n",
    "#now 1X10 bias b vector added\n",
    "b = tf.constant(np.random.randn(1,10), name = \"b\")\n",
    "with tf.Session() as sess:\n",
    "    t = tf.matmul(X,W)\n",
    "    print('t =',sess.run(t))\n",
    "    print('b = ', sess.run(b))\n",
    "    #calculate the linear function\n",
    "    z = sess.run(lin_fun(X, W,b))\n",
    "    print('z =', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "#### Calculate the linear function for input vector with 20 features and 10 activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = [[-1.8805546  -3.96946606 -1.45661758 -4.99158183  4.29165632 -9.17251828\n",
      "  -4.80516969 10.05421238  8.58201632 -7.72605462]]\n",
      "b =  [[ 0.4972691   0.2373327  -2.14444405 -0.36956243 -0.01745495  0.73140252\n",
      "   0.95449567  0.09574677  1.0334508  -0.14627327]]\n",
      "z =  [[-1.3832855  -3.73213336 -3.60106163 -5.36114425  4.27420136 -8.44111577\n",
      "  -3.85067402 10.14995915  9.61546713 -7.87232789]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(np.random.randn(1,20), name=\"X\")     #20 features\n",
    "W = tf.constant(np.random.randn(20,10), name=\"W\")    #10 activations\n",
    "b = tf.constant(np.random.randn(1,10), name='b')     #1x10 bias vector\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    t = tf.matmul(X,W)\n",
    "    print('t =',sess.run(t))\n",
    "    print('b = ', sess.run(b))\n",
    "    z = sess.run(lin_fun(X,W,b))\n",
    "    print('z = ', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us calculate the activations for the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00481853e-01 2.33819024e-02 2.65695223e-02 4.67358520e-03\n",
      "  9.86268029e-01 2.15762660e-04 2.08225975e-02 9.99960924e-01\n",
      "  9.99933315e-01 3.81000846e-04]]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = sess.run(tf.sigmoid(z))\n",
    "    print(a)\n",
    "    #The index of the largest entry, the choice\n",
    "    print(tf.argmax(a, axis=1).eval())  #the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4: \n",
    "#### Try working the same (the activations a, and the index of the max entry in each column) for a 5x5 matrix X, 5x3 matrix W and appropriate b vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90946291 0.9937326  0.77963643]\n",
      " [0.83993068 0.01280862 0.64267794]\n",
      " [0.52497656 0.00616977 0.17312897]\n",
      " [0.82515619 0.00700432 0.31356929]\n",
      " [0.95898659 0.68184104 0.78902589]]\n",
      "[1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(np.random.randn(5,5), name='X')\n",
    "W = tf.constant(np.random.randn(5,3), name='W')\n",
    "b = tf.constant(np.random.randn(1,3), name='b')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(lin_fun(X,W,b))\n",
    "    a = sess.run(tf.sigmoid(z))\n",
    "    print(a)\n",
    "    print(tf.argmax(a,axis=1).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neural Networks -  Mutilayers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = [[ 1.70121682 -1.62706074 -0.18924164 -1.41491851 -2.88615108 -1.10396498\n",
      "   0.65810806 -0.23895881  2.19750782 -1.5547158   1.28408889  0.02355386\n",
      "  -2.40309095 -2.1223578   0.99424222  1.07489665  1.87616587 -3.20846533\n",
      "  -3.30278407 -1.31521552]\n",
      " [ 0.58289675 -1.22631104  0.43508554 -0.60279374 -0.97048915 -2.11769391\n",
      "  -0.84678621 -0.1974878   1.28243424  0.51543104 -1.59911334  0.54260597\n",
      "  -0.40830782 -2.34240684 -2.75400065  0.38536477 -0.79593992 -1.4294501\n",
      "  -1.9398684  -0.24621014]]\n",
      "t2 = [[ -9.76588684  -2.53390881  -5.99305799   1.53001142  -2.11687331\n",
      "    4.42344809 -12.6956139   -3.83823601  -6.46113219   5.3011592\n",
      "  -12.61066027  -7.12376503   8.64522211 -18.1649041    2.89023458]\n",
      " [ -5.9804357    2.86481399  -2.95527775  -8.98020707   5.10571433\n",
      "    5.94252481  -2.76498024  -7.66044768   0.33286772  -1.21344299\n",
      "   -6.92441945  -1.90733013   8.12604065 -11.95382493   0.8442229 ]]\n",
      "b1 =  [[-0.07094967]]\n",
      "b2 =  [[0.03406586]]\n",
      "z1 = [[ 1.63026714 -1.69801041 -0.26019132 -1.48586819 -2.95710076 -1.17491466\n",
      "   0.58715838 -0.30990848  2.12655814 -1.62566548  1.21313922 -0.04739582\n",
      "  -2.47404063 -2.19330748  0.92329255  1.00394697  1.80521619 -3.279415\n",
      "  -3.37373375 -1.38616519]\n",
      " [ 0.51194708 -1.29726071  0.36413586 -0.67374341 -1.04143882 -2.18864359\n",
      "  -0.91773589 -0.26843748  1.21148456  0.44448137 -1.67006302  0.47165629\n",
      "  -0.47925749 -2.41335651 -2.82495033  0.3144151  -0.86688959 -1.50039977\n",
      "  -2.01081807 -0.31715982]]\n",
      "z2 = [[ -9.73182098  -2.49984295  -5.95899213   1.56407728  -2.08280745\n",
      "    4.45751396 -12.66154803  -3.80417014  -6.42706632   5.33522506\n",
      "  -12.5765944   -7.08969917   8.67928798 -18.13083823   2.92430044]\n",
      " [ -5.94636984   2.89887985  -2.92121189  -8.9461412    5.1397802\n",
      "    5.97659068  -2.73091438  -7.62638182   0.36693358  -1.17937712\n",
      "   -6.89035358  -1.87326426   8.16010651 -11.91975907   0.87828877]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "#first the fearure vector of dimension 1x10\n",
    "X = tf.constant(np.random.randn(2,10), name = \"X\")\n",
    "#the weights matrix W of dimension 10x10 that produces 10 activations\n",
    "W1 = tf.constant(np.random.randn(10,20), name = \"W1\")\n",
    "W2 = tf.constant(np.random.randn(20,15), name = \"W2\")\n",
    "#now 1X10 bias b vector added\n",
    "b1 = tf.constant(np.random.randn(1,1), name = \"b1\")\n",
    "b2 = tf.constant(np.random.randn(1,1), name = \"b2\")\n",
    "with tf.Session() as sess:\n",
    "    t1 = tf.matmul(X,W1)\n",
    "    t2 = tf.matmul(t1,W2)\n",
    "    print('t1 =',sess.run(t1))\n",
    "    print('t2 =',sess.run(t2))\n",
    "    print('b1 = ', sess.run(b1))\n",
    "    print('b2 = ', sess.run(b2))\n",
    "    #calculate the linear function\n",
    "    z1 = sess.run(lin_fun(X, W1,b1))\n",
    "    z2 = sess.run(lin_fun(t1, W2,b2))\n",
    "    print('z1 =', z1)\n",
    "    print('z2 =', z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 12]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.argmax(z2, axis=1).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 5:\n",
    "#### Write the code for a neural network algorithm where input is 5x10 matrix, first layer has 20 activations, the second has 15, the third has 20, and the multiclassification output has 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 =  [[ -1.08000371   0.5739863    2.69522937  -2.87023972   0.53528184\n",
      "    5.30545654   0.9228641    5.99089519   4.62482081  -0.68012586\n",
      "   -4.66142356   3.3322048   -5.44911842  -1.53937687   1.68942127\n",
      "   -1.32224183   1.30442347   1.80407338   4.73213777   1.20305486]\n",
      " [  0.60396624  -1.96363422  -1.79466465   3.30220639  -5.08630385\n",
      "    3.86470833   6.14063237   0.27559071  -1.47517721   1.41696779\n",
      "   -0.59904935   0.14347314   0.90410854  -2.16343364   2.43257249\n",
      "   -0.01267571  -0.67353074   2.20289598   2.81399876  -6.67031613]\n",
      " [  2.35934527   1.38875148   0.26833781  -0.92991011   2.04458768\n",
      "   -1.34757159   1.38849419   0.45125217  -0.79773443  -3.92290062\n",
      "    1.14322825  -2.13118471  -0.68368382  -4.37336123   1.33492066\n",
      "    0.24055074   0.52661102   2.84682108  -0.52686645   2.65455451]\n",
      " [ -1.28740666   2.48105255   1.35657981  -0.11098387   0.23706786\n",
      "   -2.16368006  -1.57245473   1.18480708  -0.53468199  -5.01983669\n",
      "    0.11379635  -2.69011468   0.59995688  -4.4381233    3.09937737\n",
      "    0.77185186  -0.53681292   4.01215883   2.98039713  -1.76153984]\n",
      " [ -0.78148905  -0.56883158  -0.68838932  -5.91369986   1.08477824\n",
      "   11.05645191   2.69479095   9.05167792   3.69939774   3.23192241\n",
      "  -10.55576678   5.52852655  -4.03143289  -1.61617889  -1.30984623\n",
      "    2.45749178   5.10580634   1.90460427   6.96165289  -2.92479893]]\n",
      "z2 =  [[-5.28443073e+00 -1.31819641e+01  5.99272693e-01  1.50050610e+01\n",
      "  -1.72007700e+01 -3.59746084e+00  7.33677316e+00  5.03519317e+00\n",
      "   2.00423761e+00  8.09158052e-01 -7.09114305e+00 -1.97587563e+01\n",
      "   1.53286040e+01 -5.86275483e+00  2.25153262e+01]\n",
      " [-2.59989462e+00 -1.06705024e+01  3.25554439e+00  8.73967679e+00\n",
      "   6.72003977e+00 -6.74808241e+00  1.04859496e+01  8.59438989e+00\n",
      "   3.89241566e+00 -1.66119086e+01  1.86186461e+01 -1.22677294e+00\n",
      "  -8.16866503e+00  1.62101817e+01 -4.33035997e+00]\n",
      " [-8.88679350e+00  3.77048258e+00 -7.54628363e+00 -5.59738188e+00\n",
      "  -9.54284173e+00  6.91873131e+00 -3.47835488e+00  1.61584318e+00\n",
      "  -4.18975270e+00  1.01931646e+01  3.01967159e+00  1.58285118e+01\n",
      "   5.17062456e+00  1.03243617e+00 -1.58085882e+01]\n",
      " [-6.22582468e+00  4.47177402e-02 -8.93793825e+00 -3.73132316e+00\n",
      "   1.64873753e+01  4.42635387e+00  4.45165599e+00 -5.00488855e+00\n",
      "   3.84925182e+00  1.57448073e+01  2.83890306e+01  1.17413009e+01\n",
      "   9.53990473e+00 -8.02141335e+00 -1.72341240e+01]\n",
      " [ 6.81542872e+00 -3.65941742e+01  7.57818912e+00  1.40575300e+01\n",
      "  -6.37424306e+00 -5.53846475e+00  6.64499037e+00  9.19434913e+00\n",
      "   5.21142107e+00 -3.81591764e+01 -3.00042852e+01 -5.38540815e+01\n",
      "   7.35633860e+00  5.40086904e+00  3.21534196e+01]]\n",
      "z3 =  [[   3.97348131   -2.73787588  -21.071334    -11.03415825   -2.65034164\n",
      "    54.54061568   29.98353724   -1.45009741    9.9442844     3.0702924\n",
      "   -68.83452323   67.92649272   -1.1129023    17.56362647   23.90937962\n",
      "    38.13059188   31.59939728   17.04269628   20.94766234    2.07632488]\n",
      " [  28.54946182   14.10776396    6.84702001   62.44815237   -3.10755746\n",
      "    -8.82554687   47.7273776    67.71589394  -28.3927489    22.49513021\n",
      "    55.08490401   56.43101918   40.62332263   -2.41256793   23.12937107\n",
      "     0.45017164    8.67025297  -61.21648012  -65.42972852   37.63913786]\n",
      " [   8.8935993    20.6214099    31.24742427   20.30563121  -25.1433013\n",
      "    -5.97531505  -67.69355937  -10.91653163    1.41164213   -4.18717192\n",
      "    66.49296317  -29.32601968  -18.46771612    5.33267007   10.7839208\n",
      "     2.74543673    2.86195625   45.26560326   47.26135151   37.39716375]\n",
      " [  53.63220819  -22.40947051   63.094342     22.21008503   15.98776747\n",
      "     9.68957981  -86.02728719    4.68480262   19.23625736   38.72818952\n",
      "   142.68298359   44.27943129   37.28749051  -45.24638932    3.29104414\n",
      "   -14.01067664  -29.77876064    4.74447104  -51.46617032   14.6233069 ]\n",
      " [ -33.32697965  -23.17924673 -124.70598095   12.43495512   29.96579964\n",
      "    83.723481    127.61599424   26.1251166     6.25078602  -17.26336221\n",
      "  -200.49532339  116.33987052  -62.05124999    7.81414056  -20.94957542\n",
      "    36.58102001   71.98982441  -38.83508963  -90.90585816   25.71158636]]\n",
      "z4 =  [[  11.69903384  146.61698649   91.21893733  101.42309677 -195.14477789]\n",
      " [-166.12518858  164.34909547  -56.82920722   21.13804348  196.99482618]\n",
      " [ 144.07869929  -35.25015768   21.45464539 -180.35035766 -104.78416896]\n",
      " [  12.76885632  -46.82870019  -94.80398302  -71.54573157  298.93228024]\n",
      " [ -58.36872474  177.75028102  119.91500143  255.7632023   -90.91448612]]\n",
      "argmax:  [1 4 0 4 3]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#((XW + b)W2 +b2 ...)Wn +bn\n",
    "\n",
    "#weights\n",
    "X = tf.constant(np.random.randn(5,10))\n",
    "W1 = tf.constant(np.random.randn(10,20))\n",
    "W2 = tf.constant(np.random.randn(20,15))\n",
    "W3 = tf.constant(np.random.randn(15,20))\n",
    "W4 = tf.constant(np.random.randn(20,5))\n",
    "\n",
    "#bias\n",
    "b1 = tf.constant(np.random.randn(1,20))\n",
    "b2 = tf.constant(np.random.randn(1,15))\n",
    "b3 = tf.constant(np.random.randn(1,20))\n",
    "b4 = tf.constant(np.random.randn(1,5))\n",
    "\n",
    "#layers\n",
    "z1 = lin_fun(X,W1,b1)\n",
    "z2 = lin_fun(z1,W2,b2)\n",
    "z3 = lin_fun(z2,W3,b3)\n",
    "z4 = lin_fun(z3,W4,b4)\n",
    "\n",
    "#argmax\n",
    "mpo = tf.argmax(z4, axis=1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('z1 = ',z1.eval())\n",
    "    print('z2 = ',z2.eval())\n",
    "    print('z3 = ',z3.eval())\n",
    "    print('z4 = ',z4.eval())\n",
    "    print('argmax: ',mpo.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax calcluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
